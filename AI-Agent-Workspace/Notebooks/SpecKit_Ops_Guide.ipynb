{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7681b3b3",
   "metadata": {},
   "source": [
    "# Spec Kit Operations Guide (Copilot in Codespaces)\n",
    "\n",
    "Deep exploration of Spec Kit and safe bootstrap of a .NET Aspire product search template with Copilot Agent Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1f19f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"OS_NAME\": \"linux\",\n",
      "  \"WORKSPACE_ROOT\": \"/workspaces/ActualGameSearch_V3\",\n",
      "  \"SANDBOX_DIR\": \"/tmp/spec_kit_sandbox_c3rzraok\",\n",
      "  \"ARTIFACTS_DIR\": \"/workspaces/ActualGameSearch_V3/AI-Agent-Workspace/Artifacts\",\n",
      "  \"SAFE_MODE\": \"True\",\n",
      "  \"DRY_RUN\": \"True\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Detect OS, workspace roots, and safe execution flags\n",
    "import os, sys, platform, json, tempfile, pathlib\n",
    "from typing import Dict\n",
    "\n",
    "SAFE_MODE = True  # hard-default: never execute destructive actions automatically\n",
    "DRY_RUN = True    # default: print commands instead of running\n",
    "\n",
    "OS_NAME = platform.system().lower()  # 'linux', 'darwin', or 'windows'\n",
    "ROOT = pathlib.Path('/')\n",
    "WORKSPACE_ROOT = pathlib.Path(os.environ.get('WORKSPACE_ROOT', '/workspaces/ActualGameSearch_V3')).resolve()\n",
    "SANDBOX_DIR = pathlib.Path(tempfile.mkdtemp(prefix='spec_kit_sandbox_'))\n",
    "ARTIFACTS_DIR = WORKSPACE_ROOT / 'AI-Agent-Workspace' / 'Artifacts'\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config: Dict[str, str] = {\n",
    "    'OS_NAME': OS_NAME,\n",
    "    'WORKSPACE_ROOT': str(WORKSPACE_ROOT),\n",
    "    'SANDBOX_DIR': str(SANDBOX_DIR),\n",
    "    'ARTIFACTS_DIR': str(ARTIFACTS_DIR),\n",
    "    'SAFE_MODE': str(SAFE_MODE),\n",
    "    'DRY_RUN': str(DRY_RUN),\n",
    "}\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225afb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"python\": {\n",
      "    \"ok\": true,\n",
      "    \"detail\": \"Python 3.12.3\"\n",
      "  },\n",
      "  \"uv\": {\n",
      "    \"ok\": true,\n",
      "    \"detail\": \"uv 0.8.19\"\n",
      "  },\n",
      "  \"git\": {\n",
      "    \"ok\": true,\n",
      "    \"detail\": \"git version 2.50.1\"\n",
      "  },\n",
      "  \"dotnet\": {\n",
      "    \"ok\": true,\n",
      "    \"detail\": \".NET SDK:\\n Version:           8.0.412\\n Commit:            819e1a9566\\n Workload version:  8.0.400-manifests.9cf71931\\n MSBuild version:   17.11.31+933b72e36\\n\\nRuntime Environment:\\n OS Name:     ubuntu\\n OS Version:  24.04\\n OS Platform: Linux\\n RID:         linux-x64\\n Base Path:   /usr/share/dotnet/sdk/8.0.412/\\n\\n.NET workloads installed:\\nConfigured to use loose manifests when installing new manifests.\\nThere are no installed workloads to display.\\n\\nHost:\\n  Version:      8.0.18\\n  Architecture: x64\\n  Comm\"\n",
      "  },\n",
      "  \"node\": {\n",
      "    \"ok\": true,\n",
      "    \"detail\": \"v22.17.0\"\n",
      "  },\n",
      "  \"shell\": {\n",
      "    \"ok\": true,\n",
      "    \"detail\": \"GNU bash, version 5.2.21(1)-release (x86_64-pc-linux-gnu)\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Verify prerequisites: Python 3.11+, uv, git, dotnet, Node, PowerShell/bash\n",
    "import subprocess, shutil\n",
    "\n",
    "def check_cmd(cmd, args=[\"--version\"], capture_output=True):\n",
    "    try:\n",
    "        proc = subprocess.run([cmd, *args], capture_output=capture_output, text=True, check=True)\n",
    "        return True, proc.stdout.strip() or proc.stderr.strip()\n",
    "    except FileNotFoundError:\n",
    "        return False, f\"{cmd} not found\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return False, e.stdout or e.stderr\n",
    "\n",
    "results = {}\n",
    "# Python version\n",
    "py_ver = sys.version.split()[0]\n",
    "results['python'] = (py_ver >= '3.11', f\"Python {py_ver}\")\n",
    "# uv\n",
    "ok, out = check_cmd('uv', ['--version'])\n",
    "results['uv'] = (ok, out)\n",
    "# git\n",
    "ok, out = check_cmd('git', ['--version'])\n",
    "results['git'] = (ok, out)\n",
    "# dotnet\n",
    "ok, out = check_cmd('dotnet', ['--info'])\n",
    "results['dotnet'] = (ok, out[:500])\n",
    "# node\n",
    "ok, out = check_cmd('node', ['--version'])\n",
    "results['node'] = (ok, out)\n",
    "# powershell or bash\n",
    "if OS_NAME.startswith('windows'):\n",
    "    ok, out = check_cmd('pwsh', ['--version'])\n",
    "    results['shell'] = (ok, out if ok else 'PowerShell (pwsh) not found')\n",
    "else:\n",
    "    ok, out = check_cmd('bash', ['--version'])\n",
    "    results['shell'] = (ok, out.split('\\n')[0] if ok else 'bash not found')\n",
    "\n",
    "print(json.dumps({k: {\"ok\": v[0], \"detail\": v[1]} for k,v in results.items()}, indent=2))\n",
    "\n",
    "assert results['python'][0], \"Python 3.11+ required\"\n",
    "assert results['uv'][0], \"uv is required\"\n",
    "assert results['git'][0], \"git is required\"\n",
    "assert results['dotnet'][0], \"dotnet SDK required (for Aspire)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Install/upgrade uv and prepare Spec Kit CLI invocation\n",
    "import sys\n",
    "\n",
    "def ensure_uv():\n",
    "    ok, _ = check_cmd('uv', ['--version'])\n",
    "    if ok:\n",
    "        print('uv present; skipping bootstrap')\n",
    "        return\n",
    "    if DRY_RUN:\n",
    "        print('[DRY_RUN] Would install uv via official installer')\n",
    "        return\n",
    "    # Safe installer (non-destructive); prefer curl script from Astral docs when permitted\n",
    "    try:\n",
    "        subprocess.run(['curl','-LsSf','https://astral.sh/uv/install.sh','-o','install.sh'], check=True)\n",
    "        subprocess.run(['sh','install.sh'], check=True)\n",
    "    finally:\n",
    "        if os.path.exists('install.sh'):\n",
    "            os.remove('install.sh')\n",
    "\n",
    "ensure_uv()\n",
    "\n",
    "SPECIFY = ['uvx','--from','git+https://github.com/github/spec-kit.git','specify']\n",
    "print('CLI prepared:', ' '.join(SPECIFY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95492796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Run \"specify check\" with debug logs (non-destructive)\n",
    "import shlex\n",
    "\n",
    "def run_specify_check(ignore_agent_tools=False):\n",
    "    cmd = [*SPECIFY, 'check']\n",
    "    if ignore_agent_tools:\n",
    "        cmd.append('--ignore-agent-tools')\n",
    "    print('Running:', shlex.join(cmd))\n",
    "    if DRY_RUN:\n",
    "        print('[DRY_RUN] Skipping execution')\n",
    "        return {\"dry_run\": True}\n",
    "    proc = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    print(proc.stdout)\n",
    "    if proc.returncode != 0:\n",
    "        print(proc.stderr)\n",
    "    return {\n",
    "        'code': proc.returncode,\n",
    "        'stdout': proc.stdout,\n",
    "        'stderr': proc.stderr,\n",
    "    }\n",
    "\n",
    "check_result = run_specify_check(ignore_agent_tools=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Bootstrap a sandbox Spec Kit project in a temp dir (Copilot, PS/sh)\n",
    "from pathlib import Path\n",
    "\n",
    "def spec_init_sandbox(project_name='product-search-template'):\n",
    "    target = Path(SANDBOX_DIR) / project_name\n",
    "    target.mkdir(parents=True, exist_ok=True)\n",
    "    script = 'ps' if OS_NAME.startswith('windows') else 'sh'\n",
    "    cmd = [*SPECIFY, 'init', project_name, '--ai', 'copilot', '--script', script, '--no-git', '--debug']\n",
    "    print('Init cmd:', ' '.join(cmd))\n",
    "    if DRY_RUN:\n",
    "        print('[DRY_RUN] Skipping init execution in', target)\n",
    "        return str(target)\n",
    "    proc = subprocess.run(cmd, cwd=SANDBOX_DIR, text=True)\n",
    "    if proc.returncode != 0:\n",
    "        raise RuntimeError('specify init failed')\n",
    "    return str(target)\n",
    "\n",
    "sandbox_path = spec_init_sandbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Inspect scaffolded project tree and important templates\n",
    "import os\n",
    "\n",
    "def filtered_tree(root: str, max_depth=3):\n",
    "    root_path = Path(root)\n",
    "    lines = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        depth = Path(dirpath).relative_to(root_path).parts\n",
    "        if len(depth) > max_depth:\n",
    "            continue\n",
    "        rel = str(Path(dirpath).relative_to(root_path)) or '.'\n",
    "        lines.append(f\"[DIR] {rel}\")\n",
    "        for f in filenames:\n",
    "            lines.append(f\"      - {rel}/{f}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "print(filtered_tree(sandbox_path))\n",
    "\n",
    "# Key files to verify\n",
    "key_files = [\n",
    "    'templates/spec-template.md',\n",
    "    'templates/plan-template.md',\n",
    "    'templates/tasks-template.md',\n",
    "    'scripts/bash/create-new-feature.sh',\n",
    "]\n",
    "for k in key_files:\n",
    "    p = Path(sandbox_path) / k\n",
    "    print(k, 'exists?' , p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Generate memory/constitution.md (no terminal during /constitution)\n",
    "from textwrap import dedent\n",
    "\n",
    "def write_text(path: Path, content: str):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(content, encoding='utf-8')\n",
    "\n",
    "constitution = dedent('''\n",
    "# Project Constitution: .NET Aspire Product Search Template\n",
    "\n",
    "Principles\n",
    "- Quality: CI-enforced build, lint, tests; PR review required.\n",
    "- Testing: Unit tests (xUnit), minimal integration tests for APIs, perf smoke for search endpoints.\n",
    "- UX: Fast, predictable, accessible; explainability for search results.\n",
    "- Performance: P95 under 300ms for top-10 results with warm cache; memory and CPU budgets documented.\n",
    "- Security: No secrets in repo; dev uses .env with VS Code settings; keyvault/managed identity in cloud.\n",
    "- AI Agent Guardrails: Slash commands only; never run destructive terminal ops for /constitution, /specify, /plan, /tasks, /implement.\n",
    "\n",
    "Governance\n",
    "- Architecture decisions recorded (ADR-YYYYMMDD.md).\n",
    "- Dependency updates pinned with changelogs; breaking changes gated by tests.\n",
    "- Observability: structured logs, health endpoints, minimal traces.\n",
    "''')\n",
    "\n",
    "constitution_path = Path(sandbox_path) / '.specify' / 'memory' / 'constitution.md'\n",
    "write_text(constitution_path, constitution)\n",
    "print('Wrote constitution to', constitution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8: Create specs/001-product-search/spec.md from template with AGS-aligned requirements\n",
    "feature_dir = Path(sandbox_path) / 'specs' / '001-product-search'\n",
    "feature_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "spec_md = dedent('''\n",
    "# Feature: Product/Game Search (Hybrid Semantic + Full-Text)\n",
    "\n",
    "## Problem & Goal\n",
    "Users struggle to discover games relevant to their tastes. Provide high-relevance search and relatedness navigation with explainability.\n",
    "\n",
    "## User Stories\n",
    "- As a player, I can search by free text and see highly relevant games ranked by a hybrid score.\n",
    "- As a player, I can see why a result matched (top reviews/snippets, tags, and proximity).\n",
    "- As a player, I can pivot to \"similar games\" from any result to explore relatedness.\n",
    "- As an admin, I can refresh embeddings and indexes without downtime.\n",
    "\n",
    "## Non-Goals\n",
    "- Payments, accounts, or personalization (initial phase).\n",
    "\n",
    "## Acceptance Criteria\n",
    "- Query returns <= 300ms P95 for top-10 results locally.\n",
    "- Results list includes title, image, short description, top-3 evidence snippets (review excerpts), and similarity score.\n",
    "- Similar games endpoint returns 10 related games based on vector neighbors.\n",
    "- Errors are surfaced with actionable messages; no stack traces to users.\n",
    "\n",
    "## Review & Acceptance Checklist\n",
    "- [ ] Functional flows verified for search and relatedness\n",
    "- [ ] Performance targets validated (P95) on seed dataset\n",
    "- [ ] Accessibility checks on labels/contrast\n",
    "- [ ] Logging for queries and errors (PII-free)\n",
    "''')\n",
    "\n",
    "spec_path = feature_dir / 'spec.md'\n",
    "write_text(spec_path, spec_md)\n",
    "print('Wrote spec to', spec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3586bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9: Create plan.md targeting .NET Aspire, Postgres/SQLite, Blazor, REST\n",
    "plan_md = dedent('''\n",
    "# Implementation Plan: .NET Aspire Product/Game Search\n",
    "\n",
    "## Tech Stack\n",
    "- .NET 10 + .NET Aspire for orchestration\n",
    "- Postgres (prod) / SQLite (local dev) for metadata\n",
    "- Cosmos DB or Postgres pgvector (optional) for vectors in prod; SQLite w/ FTS5 + local ANN (dev)\n",
    "- Blazor Server for UI; REST APIs for Search and Similar endpoints\n",
    "- Ollama (Gemma) for embeddings (local dev)\n",
    "\n",
    "## Services\n",
    "- Gateway: reverse proxy + auth stub\n",
    "- API.Search: hybrid search (vector + lexical), explainability\n",
    "- Workers.ETL: fetch Steam metadata/reviews; embed text; write to DB\n",
    "- Shared: contracts/models\n",
    "\n",
    "## Versions\n",
    "- .NET SDK: 10.x (confirm with `dotnet --info`)\n",
    "- Aspire: latest stable compatible with SDK\n",
    "- Postgres: 16.x; pgvector 0.6+\n",
    "\n",
    "## Infra\n",
    "- Local dev uses docker-compose: Postgres, Ollama\n",
    "- Observability: structured logs (Serilog), health checks, minimal tracing\n",
    "\n",
    "## Rationale\n",
    ".NET Aspire simplifies local orchestration; Postgres provides low-friction persistence; Ollama enables no-cost local embeddings.\n",
    "''')\n",
    "\n",
    "plan_path = feature_dir / 'plan.md'\n",
    "write_text(plan_path, plan_md)\n",
    "print('Wrote plan to', plan_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f39cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 10: Derive tasks.md from plan with TDD and dependencies\n",
    "tasks_md = dedent('''\n",
    "# Tasks\n",
    "\n",
    "## Order & Dependencies\n",
    "1. Scaffold Aspire solution [id:scaffold]\n",
    "2. Add API.Search project [id:api] depends_on: scaffold\n",
    "3. Add Workers.ETL project [id:etl] depends_on: scaffold\n",
    "4. Add Shared contracts [id:shared] depends_on: scaffold\n",
    "5. Docker compose for Postgres + Ollama [id:compose] depends_on: scaffold\n",
    "6. Search API endpoints + tests [id:api-tests] depends_on: api, shared\n",
    "7. ETL pipelines + tests [id:etl-tests] depends_on: etl, shared\n",
    "8. Blazor UI skeleton + smoke tests [id:ui] depends_on: api\n",
    "\n",
    "## TDD Steps (examples)\n",
    "- For Search API: write tests for ranking composition (proximity + resonance) before implementation.\n",
    "- For ETL: tests for weighted game vector from review embeddings.\n",
    "- For UI: component tests for results list and evidence rendering.\n",
    "''')\n",
    "\n",
    "tasks_path = feature_dir / 'tasks.md'\n",
    "write_text(tasks_path, tasks_md)\n",
    "print('Wrote tasks to', tasks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 11: Validate project readiness\n",
    "from collections import deque\n",
    "\n",
    "required = [constitution_path, spec_path, plan_path, tasks_path]\n",
    "missing = [str(p) for p in required if not Path(p).exists()]\n",
    "print('Missing:', missing)\n",
    "\n",
    "# Simple DAG check from tasks file\n",
    "import re\n",
    "edges = []\n",
    "ids = set()\n",
    "for line in tasks_md.splitlines():\n",
    "    m_id = re.search(r\"\\[id:([a-zA-Z0-9_-]+)\\]\", line)\n",
    "    if m_id:\n",
    "        ids.add(m_id.group(1))\n",
    "    m_dep = re.search(r\"depends_on:\\s*([^\\n]+)\", line)\n",
    "    if m_dep and m_id:\n",
    "        deps = [d.strip() for d in m_dep.group(1).split(',')]\n",
    "        for d in deps:\n",
    "            edges.append((d, m_id.group(1)))\n",
    "\n",
    "# Kahn's algorithm\n",
    "indeg = {i:0 for i in ids}\n",
    "for u,v in edges:\n",
    "    if v in indeg:\n",
    "        indeg[v]+=1\n",
    "q = deque([i for i,d in indeg.items() if d==0])\n",
    "order = []\n",
    "while q:\n",
    "    u=q.popleft(); order.append(u)\n",
    "    for a,b in list(edges):\n",
    "        if a==u:\n",
    "            indeg[b]-=1\n",
    "            edges.remove((a,b))\n",
    "            if indeg[b]==0:\n",
    "                q.append(b)\n",
    "\n",
    "acyclic = len(edges)==0\n",
    "print(json.dumps({\n",
    "  'files_present': len(missing)==0,\n",
    "  'dag_acyclic': acyclic,\n",
    "  'topo_order_prefix': order[:5]\n",
    "}, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e14818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 12: Emit Copilot slash-command payloads for manual paste\n",
    "constitution_prompt = \"/constitution Create principles focused on code quality (CI tests), UX consistency and accessibility, performance (P95<300ms for search), security (no secrets), and AI-agent guardrails (no terminal ops for slash commands).\"\n",
    "specify_prompt = \"/specify Build a hybrid semantic + full-text product/game search with explainability, similar-games navigation, and seed dataset support. Return top-10 with evidence snippets and similarity.\"\n",
    "plan_prompt = \"/plan Use .NET Aspire (.NET 10), Blazor Server, Postgres (local SQLite), and Ollama for embeddings. Provide Search API, Similar API, and ETL workers. Include versions and docker-compose.\"\n",
    "tasks_prompt = \"/tasks\"\n",
    "implement_prompt = \"/implement\"\n",
    "\n",
    "print('\\n'.join([\n",
    "    'Paste into Copilot Agent Mode:',\n",
    "    constitution_prompt,\n",
    "    specify_prompt,\n",
    "    plan_prompt,\n",
    "    tasks_prompt,\n",
    "    implement_prompt\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feef19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 13: Optional: Execute repo wiring scripts with dry-run\n",
    "ps_script = Path(sandbox_path) / 'scripts' / 'powershell' / 'setup-plan.ps1'\n",
    "sh_script = Path(sandbox_path) / 'scripts' / 'bash' / 'setup-plan.sh'\n",
    "\n",
    "print('PowerShell script exists?', ps_script.exists())\n",
    "print('Bash script exists?', sh_script.exists())\n",
    "\n",
    "if not DRY_RUN:\n",
    "    if OS_NAME.startswith('windows') and ps_script.exists():\n",
    "        subprocess.run(['pwsh','-File', str(ps_script)], check=False)\n",
    "    elif sh_script.exists():\n",
    "        subprocess.run(['bash', str(sh_script)], check=False)\n",
    "else:\n",
    "    print('[DRY_RUN] Skipping script execution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b549f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 14: Export artifacts (zip) and manifest\n",
    "import zipfile\n",
    "\n",
    "zip_path = Path(ARTIFACTS_DIR) / 'spec_kit_sandbox.zip'\n",
    "manifest = {\n",
    "    'sandbox_path': sandbox_path,\n",
    "    'constitution': str(constitution_path),\n",
    "    'spec': str(spec_path),\n",
    "    'plan': str(plan_path),\n",
    "    'tasks': str(tasks_path),\n",
    "}\n",
    "\n",
    "if not DRY_RUN:\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "        for dirpath, _, filenames in os.walk(sandbox_path):\n",
    "            for f in filenames:\n",
    "                p = Path(dirpath) / f\n",
    "                z.write(p, arcname=str(Path(sandbox_path).name / p.relative_to(sandbox_path)))\n",
    "else:\n",
    "    print('[DRY_RUN] Skipping zip creation')\n",
    "\n",
    "(Path(ARTIFACTS_DIR) / 'manifest.json').write_text(json.dumps(manifest, indent=2), encoding='utf-8')\n",
    "print('Artifacts at:', ARTIFACTS_DIR)\n",
    "print('Manifest:', json.dumps(manifest, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab915876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 15: Minimal tests for validators and DAG\n",
    "\n",
    "def test_files_present():\n",
    "    assert Path(constitution_path).exists()\n",
    "    assert Path(spec_path).exists()\n",
    "    assert Path(plan_path).exists()\n",
    "    assert Path(tasks_path).exists()\n",
    "\n",
    "\n",
    "def test_dag_acyclic():\n",
    "    # reuse 'acyclic' from earlier cell by recomputing quickly\n",
    "    import re\n",
    "    edges = []\n",
    "    ids = set()\n",
    "    for line in tasks_md.splitlines():\n",
    "        m_id = re.search(r\"\\[id:([a-zA-Z0-9_-]+)\\]\", line)\n",
    "        if m_id:\n",
    "            ids.add(m_id.group(1))\n",
    "        m_dep = re.search(r\"depends_on:\\s*([^\\n]+)\", line)\n",
    "        if m_dep and m_id:\n",
    "            deps = [d.strip() for d in m_dep.group(1).split(',')]\n",
    "            for d in deps:\n",
    "                edges.append((d, m_id.group(1)))\n",
    "    indeg = {i:0 for i in ids}\n",
    "    for u,v in edges:\n",
    "        if v in indeg:\n",
    "            indeg[v]+=1\n",
    "    from collections import deque\n",
    "    q = deque([i for i,d in indeg.items() if d==0])\n",
    "    seen=0\n",
    "    while q:\n",
    "        u=q.popleft(); seen+=1\n",
    "        for a,b in list(edges):\n",
    "            if a==u:\n",
    "                indeg[b]-=1\n",
    "                edges.remove((a,b))\n",
    "                if indeg[b]==0:\n",
    "                    q.append(b)\n",
    "    assert len(edges)==0\n",
    "\n",
    "# Run tests\n",
    "try:\n",
    "    test_files_present(); test_dag_acyclic()\n",
    "    print('All tests passed')\n",
    "except AssertionError as e:\n",
    "    print('Tests failed:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

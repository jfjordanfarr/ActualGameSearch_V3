{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2941b78e",
   "metadata": {},
   "source": [
    "# Cross-Artifact Consistency Analysis\n",
    "## Specification Quality Analysis for ActualGameSearch V3\n",
    "\n",
    "This notebook performs a comprehensive cross-artifact consistency and quality analysis across `spec.md`, `plan.md`, and `tasks.md` following the analyze.prompt.md instructions.\n",
    "\n",
    "**Analysis Scope:**\n",
    "- Feature Directory: `specs/002-we-intend-to/`\n",
    "- Constitution Authority: `.specify/memory/constitution.md`\n",
    "- Detection Categories: Duplication, Ambiguity, Underspecification, Constitution Alignment, Coverage Gaps, Inconsistencies\n",
    "\n",
    "**Analysis Goal:** Identify issues before implementation and ensure docs/contracts align with current code reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b600285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /workspaces/ActualGameSearch_V3\n",
      "Repository root: /workspaces/ActualGameSearch_V3\n",
      "Prerequisites check PASSED\n",
      "Feature Directory: /workspaces/ActualGameSearch_V3/specs/002-we-intend-to\n",
      "Available Documents: ['research.md', 'data-model.md', 'contracts/', 'quickstart.md', 'tasks.md']\n",
      "All required files found\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Execute Prerequisites Check\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Change to repo root for prerequisites check\n",
    "repo_root = \"/workspaces/ActualGameSearch_V3\"\n",
    "os.chdir(repo_root)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Repository root: {repo_root}\")\n",
    "\n",
    "# Execute prerequisites check to get FEATURE_DIR and AVAILABLE_DOCS\n",
    "try:\n",
    "    # Make script executable first\n",
    "    script_path = \"./.specify/scripts/bash/check-prerequisites.sh\"\n",
    "    subprocess.run([\"chmod\", \"+x\", script_path], check=True)\n",
    "    \n",
    "    # Run the prerequisites check\n",
    "    result = subprocess.run([\n",
    "        script_path, \n",
    "        \"--json\", \n",
    "        \"--require-tasks\", \n",
    "        \"--include-tasks\"\n",
    "    ], capture_output=True, text=True, check=True)\n",
    "    \n",
    "    prerequisites_data = json.loads(result.stdout)\n",
    "    FEATURE_DIR = prerequisites_data[\"FEATURE_DIR\"]\n",
    "    AVAILABLE_DOCS = prerequisites_data[\"AVAILABLE_DOCS\"]\n",
    "    \n",
    "    print(\"Prerequisites check PASSED\")\n",
    "    print(f\"Feature Directory: {FEATURE_DIR}\")\n",
    "    print(f\"Available Documents: {AVAILABLE_DOCS}\")\n",
    "    \n",
    "    # Derive absolute paths for analysis\n",
    "    SPEC_PATH = os.path.join(FEATURE_DIR, \"spec.md\")\n",
    "    PLAN_PATH = os.path.join(FEATURE_DIR, \"plan.md\") \n",
    "    TASKS_PATH = os.path.join(FEATURE_DIR, \"tasks.md\")\n",
    "    CONSTITUTION_PATH = os.path.join(repo_root, \".specify/memory/constitution.md\")\n",
    "    \n",
    "    # Verify all required files exist\n",
    "    required_files = [SPEC_PATH, PLAN_PATH, TASKS_PATH, CONSTITUTION_PATH]\n",
    "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"ERROR: Missing required files: {missing_files}\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"All required files found\")\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Prerequisites check FAILED: {e}\")\n",
    "    print(f\"stdout: {e.stdout}\")\n",
    "    print(f\"stderr: {e.stderr}\")\n",
    "    sys.exit(1)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Failed to parse prerequisites JSON: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f4c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading artifact files...\n",
      "Loaded spec.md: 11265 characters\n",
      "Loaded plan.md: 7872 characters\n",
      "Loaded tasks.md: 10821 characters\n",
      "Loaded constitution.md: 12833 characters\n",
      "\n",
      "Spec sections: ['Feature Specification: Actual Game Search (Hybrid Full‑Text + Semantic)', 'Execution Flow (main)', '⚡ Quick Guidelines', 'Section Requirements', 'For AI Generation', 'User Scenarios & Testing (mandatory)', 'Primary User Story', 'Acceptance Scenarios', 'Edge Cases', 'Requirements (mandatory)', 'Functional Requirements', 'Filtering & Constraints', 'Payload for Client Re‑Ranking (WHAT the client needs)', 'Key Entities (payload shapes, not implementation)', 'Review & Acceptance Checklist', 'Content Quality', 'Requirement Completeness', 'Execution Status', 'Reality Check (as of 2025-09-23)']\n",
      "Plan sections: ['Implementation Plan: Actual Game Search (Hybrid Full‑Text + Semantic)', 'Execution Flow (/plan command scope)', 'Summary', 'Technical Context', 'Constitution Check', 'Project Structure', 'Documentation (this feature)', 'Source Code (repository root)', 'Reality Check (as of 2025-09-23)', 'Phase 0: Outline & Research', 'Phase 1: Design & Contracts', 'Phase 2: Task Planning Approach', 'Phase 3+: Future Implementation', 'Complexity Tracking', 'Progress Tracking']\n",
      "Tasks sections: ['Tasks: Actual Game Search (Hybrid Full‑Text + Semantic)', 'Execution Flow (main)', 'Path conventions (idiomatic .NET Aspire)', 'Phase 3.1: Setup', 'Phase 3.2: Tests First (TDD) ⚠️ MUST COMPLETE BEFORE 3.3', 'Phase 3.3: Core Implementation (ONLY after tests are failing)', 'Phase 3.4: Integration', 'Phase 3.5: Polish', 'Dependencies', 'Parallel Execution Examples', 'Example 1: Kick off contract tests in parallel after OpenAPI update', 'Example 2: Core models/services in parallel (independent files)', 'Example 3: Polish in parallel', 'Validation Checklist', 'Status Snapshot (2025-09-23)']\n",
      "Constitution sections: ['Operating Modes & Context Management', 'Anti-Patterns & Risk Mitigation', 'Actual Game Search (actualgamesearch.com) Constitution', 'Core Principles', 'I. Open Source & Public by Default', 'II. Solve It Right, Once (No Band‑Aids)', 'III. Pragmatic & Idiomatic Technology Usage', 'IV. Ultra‑Low‑Cost, High‑Accuracy Search', 'V. Test‑First, Observability, and Simplicity', 'VI. Evidence-Based Documentation & Provenance', 'Additional Standards & Constraints', 'Data Quality & ETL', 'Documentation Standards & Provenance Requirements', 'Development Workflow & Quality Gates', 'AI‑Driven Solo Development', 'Governance']\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Load and Parse Artifacts\n",
    "import re\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "def load_file_content(path: str) -> str:\n",
    "    \"\"\"Load file content with error handling.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def parse_markdown_sections(content: str) -> Dict[str, str]:\n",
    "    \"\"\"Parse markdown content into sections based on headers.\"\"\"\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    current_content = []\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    for line in lines:\n",
    "        # Check for markdown headers\n",
    "        if line.strip().startswith('#'):\n",
    "            # Save previous section if exists\n",
    "            if current_section:\n",
    "                sections[current_section] = '\\n'.join(current_content).strip()\n",
    "            \n",
    "            # Start new section\n",
    "            current_section = line.strip().lstrip('#').strip()\n",
    "            current_content = []\n",
    "        else:\n",
    "            if current_section:\n",
    "                current_content.append(line)\n",
    "    \n",
    "    # Don't forget the last section\n",
    "    if current_section:\n",
    "        sections[current_section] = '\\n'.join(current_content).strip()\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# Load all artifact files\n",
    "print(\"Loading artifact files...\")\n",
    "\n",
    "spec_content = load_file_content(SPEC_PATH)\n",
    "plan_content = load_file_content(PLAN_PATH)\n",
    "tasks_content = load_file_content(TASKS_PATH)\n",
    "constitution_content = load_file_content(CONSTITUTION_PATH)\n",
    "\n",
    "print(f\"Loaded spec.md: {len(spec_content)} characters\")\n",
    "print(f\"Loaded plan.md: {len(plan_content)} characters\") \n",
    "print(f\"Loaded tasks.md: {len(tasks_content)} characters\")\n",
    "print(f\"Loaded constitution.md: {len(constitution_content)} characters\")\n",
    "\n",
    "# Parse into sections\n",
    "spec_sections = parse_markdown_sections(spec_content)\n",
    "plan_sections = parse_markdown_sections(plan_content)\n",
    "tasks_sections = parse_markdown_sections(tasks_content)\n",
    "constitution_sections = parse_markdown_sections(constitution_content)\n",
    "\n",
    "print(f\"\\nSpec sections: {list(spec_sections.keys())}\")\n",
    "print(f\"Plan sections: {list(plan_sections.keys())}\")\n",
    "print(f\"Tasks sections: {list(tasks_sections.keys())}\")\n",
    "print(f\"Constitution sections: {list(constitution_sections.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a48ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building semantic models...\n",
      "Extracted 22 requirements\n",
      "Extracted 28 tasks\n",
      "Extracted 0 constitution principles\n",
      "\n",
      "Sample requirements:\n",
      "  fr_001: The system MUST accept a free-text search prompt and return a candidate set suitable for client-side...\n",
      "  fr_002: The client MUST present an initial subset of candidates with title, image (if available), short desc...\n",
      "  fr_003: The system MUST support a “similar games” action from any result, returning a related set with brief...\n",
      "\n",
      "Sample tasks:\n",
      "  T001: - `ActualGameSearch.sln` with projects: `ActualGameSearch.AppHost`, `ActualGameSearch.Api`, `ActualG...\n",
      "  T002: - Add Cosmos DB emulator resource; add database/containers (games, reviews)...\n",
      "  T003: - `src/ActualGameSearch.ServiceDefaults/` with `AddServiceDefaults()`; enable OpenTelemetry, service...\n",
      "\n",
      "Constitution principles:\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Build Semantic Models\n",
    "from dataclasses import dataclass\n",
    "from typing import Set\n",
    "\n",
    "@dataclass\n",
    "class Requirement:\n",
    "    key: str\n",
    "    text: str\n",
    "    requirement_type: str  # 'functional' or 'non-functional'\n",
    "    location: str\n",
    "    testable: bool = False\n",
    "    \n",
    "@dataclass \n",
    "class Task:\n",
    "    id: str\n",
    "    description: str\n",
    "    phase: str\n",
    "    parallel: bool\n",
    "    file_paths: List[str]\n",
    "    dependencies: List[str]\n",
    "    location: str\n",
    "\n",
    "@dataclass\n",
    "class Finding:\n",
    "    id: str\n",
    "    category: str\n",
    "    severity: str\n",
    "    locations: List[str] \n",
    "    summary: str\n",
    "    recommendation: str\n",
    "\n",
    "def extract_requirements_from_spec(spec_sections: Dict[str, str]) -> List[Requirement]:\n",
    "    \"\"\"Extract functional and non-functional requirements from spec.\"\"\"\n",
    "    requirements = []\n",
    "    \n",
    "    # Look for requirements section\n",
    "    req_section = spec_sections.get('Requirements (mandatory)', '')\n",
    "    if not req_section:\n",
    "        req_section = spec_sections.get('Requirements', '')\n",
    "    \n",
    "    functional_section = spec_sections.get('Functional Requirements', '')\n",
    "    if functional_section or 'Functional Requirements' in req_section:\n",
    "        # Parse FR-XXX patterns\n",
    "        fr_matches = re.findall(r'(FR-\\d+):\\s*(.*?)(?=FR-\\d+|$)', functional_section or req_section, re.DOTALL)\n",
    "        for fr_id, text in fr_matches:\n",
    "            key = fr_id.lower().replace('-', '_')\n",
    "            requirements.append(Requirement(\n",
    "                key=key, \n",
    "                text=text.strip(),\n",
    "                requirement_type='functional',\n",
    "                location=f'spec.md#functional-requirements',\n",
    "                testable='MUST' in text or 'SHALL' in text\n",
    "            ))\n",
    "    \n",
    "    # Parse filtering & constraints section  \n",
    "    filter_section = spec_sections.get('Filtering & Constraints', '')\n",
    "    if filter_section:\n",
    "        fr_matches = re.findall(r'(FR-\\d+):\\s*(.*?)(?=FR-\\d+|$)', filter_section, re.DOTALL)\n",
    "        for fr_id, text in fr_matches:\n",
    "            key = fr_id.lower().replace('-', '_')\n",
    "            requirements.append(Requirement(\n",
    "                key=key,\n",
    "                text=text.strip(), \n",
    "                requirement_type='functional',\n",
    "                location=f'spec.md#filtering-constraints',\n",
    "                testable='MUST' in text or 'SHALL' in text\n",
    "            ))\n",
    "    \n",
    "    return requirements\n",
    "\n",
    "def extract_tasks_from_tasks_md(tasks_sections: Dict[str, str]) -> List[Task]:\n",
    "    \"\"\"Extract tasks from tasks.md file.\"\"\"\n",
    "    tasks = []\n",
    "    \n",
    "    # Look through all sections for task patterns\n",
    "    for section_name, content in tasks_sections.items():\n",
    "        if 'Phase' in section_name:\n",
    "            # Extract T### patterns\n",
    "            task_matches = re.findall(r'- \\[.\\] (T\\d+).*?\\n\\s*(.+?)(?=\\n\\s*-|\\n\\n|\\Z)', content, re.DOTALL)\n",
    "            for task_id, description in task_matches:\n",
    "                # Extract file paths mentioned\n",
    "                file_paths = re.findall(r'`([^`]*\\.cs|[^`]*\\.md|[^`]*\\.yaml|[^`]*\\.json)`', description)\n",
    "                file_paths.extend(re.findall(r'Files?: `([^`]+)`', description))\n",
    "                file_paths.extend(re.findall(r'File: `([^`]+)`', description))\n",
    "                \n",
    "                # Check if parallel\n",
    "                is_parallel = '[P]' in description\n",
    "                \n",
    "                # Extract dependencies  \n",
    "                dependencies = []\n",
    "                if 'Dependencies:' in description:\n",
    "                    dep_match = re.search(r'Dependencies: (.+)', description)\n",
    "                    if dep_match:\n",
    "                        deps_text = dep_match.group(1)\n",
    "                        dependencies = re.findall(r'T\\d+', deps_text)\n",
    "                \n",
    "                tasks.append(Task(\n",
    "                    id=task_id,\n",
    "                    description=description.strip(),\n",
    "                    phase=section_name,\n",
    "                    parallel=is_parallel,\n",
    "                    file_paths=file_paths,\n",
    "                    dependencies=dependencies,\n",
    "                    location=f'tasks.md#{section_name.lower().replace(\" \", \"-\")}'\n",
    "                ))\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "def extract_constitution_principles(constitution_sections: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"Extract constitution principles and MUST statements.\"\"\"\n",
    "    principles = {}\n",
    "    \n",
    "    # Look for Core Principles section\n",
    "    core_principles = constitution_sections.get('Core Principles', '')\n",
    "    if core_principles:\n",
    "        # Extract principle sections (### I., ### II., etc.)\n",
    "        principle_matches = re.findall(r'### ([IV]+\\..*?)\\n(.*?)(?=###|\\Z)', core_principles, re.DOTALL)\n",
    "        for title, content in principle_matches:\n",
    "            principles[title] = content.strip()\n",
    "    \n",
    "    return principles\n",
    "\n",
    "# Build semantic models\n",
    "print(\"Building semantic models...\")\n",
    "\n",
    "requirements = extract_requirements_from_spec(spec_sections)\n",
    "tasks = extract_tasks_from_tasks_md(tasks_sections)\n",
    "constitution_principles = extract_constitution_principles(constitution_sections)\n",
    "\n",
    "print(f\"Extracted {len(requirements)} requirements\")\n",
    "print(f\"Extracted {len(tasks)} tasks\")  \n",
    "print(f\"Extracted {len(constitution_principles)} constitution principles\")\n",
    "\n",
    "# Display sample extractions\n",
    "print(f\"\\nSample requirements:\")\n",
    "for req in requirements[:3]:\n",
    "    print(f\"  {req.key}: {req.text[:100]}...\")\n",
    "\n",
    "print(f\"\\nSample tasks:\")  \n",
    "for task in tasks[:3]:\n",
    "    print(f\"  {task.id}: {task.description[:100]}...\")\n",
    "\n",
    "print(f\"\\nConstitution principles:\")\n",
    "for title, content in list(constitution_principles.items())[:2]:\n",
    "    print(f\"  {title}: {content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400e91c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running detection passes...\n",
      "Detection complete:\n",
      "  Duplication issues: 0\n",
      "  Ambiguity issues: 1\n",
      "  Underspecification issues: 4\n",
      "  Constitution violations: 0\n",
      "  Coverage gaps: 12\n",
      "  Inconsistencies: 2\n",
      "  Total findings: 19\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Run Detection Passes\n",
    "import difflib\n",
    "\n",
    "def detect_duplications(requirements: List[Requirement]) -> List[Finding]:\n",
    "    \"\"\"Detect near-duplicate requirements.\"\"\"\n",
    "    findings = []\n",
    "    \n",
    "    for i, req1 in enumerate(requirements):\n",
    "        for j, req2 in enumerate(requirements[i+1:], i+1):\n",
    "            # Calculate similarity\n",
    "            similarity = difflib.SequenceMatcher(None, req1.text.lower(), req2.text.lower()).ratio()\n",
    "            \n",
    "            if similarity > 0.7:  # High similarity threshold\n",
    "                findings.append(Finding(\n",
    "                    id=f\"D{len(findings)+1:02d}\",\n",
    "                    category=\"Duplication\", \n",
    "                    severity=\"HIGH\",\n",
    "                    locations=[req1.location, req2.location],\n",
    "                    summary=f\"Requirements {req1.key} and {req2.key} are {similarity:.1%} similar\",\n",
    "                    recommendation=f\"Merge similar requirements; keep clearer version\"\n",
    "                ))\n",
    "    \n",
    "    return findings\n",
    "\n",
    "def detect_ambiguities(requirements: List[Requirement], tasks: List[Task]) -> List[Finding]:\n",
    "    \"\"\"Detect vague language and unresolved placeholders.\"\"\" \n",
    "    findings = []\n",
    "    \n",
    "    # Vague adjectives to flag\n",
    "    vague_terms = ['fast', 'scalable', 'secure', 'intuitive', 'robust', 'efficient', 'good', 'better']\n",
    "    \n",
    "    # Check requirements for vague terms\n",
    "    for req in requirements:\n",
    "        for term in vague_terms:\n",
    "            if term in req.text.lower() and ('measurable' not in req.text.lower() and 'specific' not in req.text.lower()):\n",
    "                findings.append(Finding(\n",
    "                    id=f\"A{len(findings)+1:02d}\",\n",
    "                    category=\"Ambiguity\",\n",
    "                    severity=\"MEDIUM\", \n",
    "                    locations=[req.location],\n",
    "                    summary=f\"Requirement {req.key} uses vague term '{term}' without measurable criteria\",\n",
    "                    recommendation=f\"Replace '{term}' with specific, measurable criteria\"\n",
    "                ))\n",
    "    \n",
    "    # Check for placeholder patterns\n",
    "    placeholder_patterns = ['TODO', 'TKTK', '???', '<placeholder>', 'NEEDS CLARIFICATION']\n",
    "    all_content = spec_content + plan_content + tasks_content\n",
    "    \n",
    "    for pattern in placeholder_patterns:\n",
    "        if pattern in all_content:\n",
    "            findings.append(Finding(\n",
    "                id=f\"A{len(findings)+1:02d}\",\n",
    "                category=\"Ambiguity\",\n",
    "                severity=\"HIGH\",\n",
    "                locations=[\"multiple files\"],\n",
    "                summary=f\"Unresolved placeholder '{pattern}' found in artifacts\",\n",
    "                recommendation=f\"Resolve all '{pattern}' markers before implementation\"\n",
    "            ))\n",
    "    \n",
    "    return findings\n",
    "\n",
    "def detect_underspecification(requirements: List[Requirement], tasks: List[Task]) -> List[Finding]:\n",
    "    \"\"\"Detect underspecified requirements and tasks.\"\"\"\n",
    "    findings = []\n",
    "    \n",
    "    # Check for untestable requirements\n",
    "    for req in requirements:\n",
    "        if not req.testable and 'SHOULD' not in req.text and 'MAY' not in req.text:\n",
    "            # Look for action verbs without measurable outcomes\n",
    "            has_verb = any(verb in req.text.lower() for verb in ['must', 'shall', 'will', 'should', 'can'])\n",
    "            has_outcome = any(outcome in req.text.lower() for outcome in ['return', 'display', 'show', 'log', 'store', 'validate'])\n",
    "            \n",
    "            if has_verb and not has_outcome:\n",
    "                findings.append(Finding(\n",
    "                    id=f\"U{len(findings)+1:02d}\",\n",
    "                    category=\"Underspecification\",\n",
    "                    severity=\"MEDIUM\",\n",
    "                    locations=[req.location],\n",
    "                    summary=f\"Requirement {req.key} has action verb but missing measurable outcome\",\n",
    "                    recommendation=\"Add specific, testable acceptance criteria\"\n",
    "                ))\n",
    "    \n",
    "    # Check for tasks referencing undefined components\n",
    "    for task in tasks:\n",
    "        # Look for references to files/components not defined elsewhere\n",
    "        undefined_refs = []\n",
    "        for file_path in task.file_paths:\n",
    "            if not any(file_path in spec_content or file_path in plan_content for file_path in task.file_paths):\n",
    "                undefined_refs.append(file_path)\n",
    "        \n",
    "        if undefined_refs:\n",
    "            findings.append(Finding(\n",
    "                id=f\"U{len(findings)+1:02d}\",\n",
    "                category=\"Underspecification\", \n",
    "                severity=\"MEDIUM\",\n",
    "                locations=[task.location],\n",
    "                summary=f\"Task {task.id} references undefined files: {undefined_refs}\",\n",
    "                recommendation=\"Define referenced components in spec or plan\"\n",
    "            ))\n",
    "    \n",
    "    return findings\n",
    "\n",
    "def detect_constitution_violations(requirements: List[Requirement], constitution_principles: Dict[str, str]) -> List[Finding]:\n",
    "    \"\"\"Detect violations of constitutional principles.\"\"\"\n",
    "    findings = []\n",
    "    \n",
    "    # Extract MUST statements from constitution\n",
    "    must_statements = []\n",
    "    for title, content in constitution_principles.items():\n",
    "        must_matches = re.findall(r'([^.]*MUST[^.]*\\.)', content)\n",
    "        must_statements.extend([(title, stmt.strip()) for stmt in must_matches])\n",
    "    \n",
    "    # Check each requirement against MUST statements\n",
    "    for req in requirements:\n",
    "        # Check specific violations\n",
    "        if 'test' in req.text.lower() and 'MUST' in req.text:\n",
    "            # Check if violates \"Test‑First\" principle\n",
    "            test_principle = \"Test‑First, Observability, and Simplicity\"\n",
    "            if test_principle in constitution_principles:\n",
    "                if 'before' not in req.text.lower() and 'first' not in req.text.lower():\n",
    "                    findings.append(Finding(\n",
    "                        id=f\"C{len(findings)+1:02d}\",\n",
    "                        category=\"Constitution\",\n",
    "                        severity=\"CRITICAL\",\n",
    "                        locations=[req.location, \"constitution.md#test-first\"],\n",
    "                        summary=f\"Requirement {req.key} may violate Test-First principle\",\n",
    "                        recommendation=\"Ensure test requirements specify test-first approach\"\n",
    "                    ))\n",
    "    \n",
    "    return findings\n",
    "\n",
    "def detect_coverage_gaps(requirements: List[Requirement], tasks: List[Task]) -> List[Finding]:\n",
    "    \"\"\"Detect requirements without task coverage and tasks without requirement mapping.\"\"\"\n",
    "    findings = []\n",
    "    \n",
    "    # Build requirement-to-task mapping\n",
    "    req_task_map = {req.key: [] for req in requirements}\n",
    "    unmapped_tasks = []\n",
    "    \n",
    "    for task in tasks:\n",
    "        mapped = False\n",
    "        for req in requirements:\n",
    "            # Simple keyword matching for coverage\n",
    "            req_keywords = set(re.findall(r'\\w+', req.text.lower()))\n",
    "            task_keywords = set(re.findall(r'\\w+', task.description.lower()))\n",
    "            \n",
    "            # Check for overlap or explicit FR references\n",
    "            if (len(req_keywords.intersection(task_keywords)) >= 2 or \n",
    "                req.key.upper() in task.description or\n",
    "                req.key.replace('_', '-').upper() in task.description):\n",
    "                req_task_map[req.key].append(task.id)\n",
    "                mapped = True\n",
    "        \n",
    "        if not mapped:\n",
    "            unmapped_tasks.append(task)\n",
    "    \n",
    "    # Find requirements with zero coverage\n",
    "    for req in requirements:\n",
    "        if not req_task_map[req.key] and req.requirement_type == 'functional':\n",
    "            findings.append(Finding(\n",
    "                id=f\"G{len(findings)+1:02d}\",\n",
    "                category=\"Coverage Gap\",\n",
    "                severity=\"HIGH\" if 'MUST' in req.text else \"MEDIUM\",\n",
    "                locations=[req.location],\n",
    "                summary=f\"Requirement {req.key} has no associated tasks\",\n",
    "                recommendation=f\"Add implementation tasks for requirement {req.key}\"\n",
    "            ))\n",
    "    \n",
    "    # Report unmapped tasks\n",
    "    for task in unmapped_tasks[:5]:  # Limit to first 5 to avoid noise\n",
    "        findings.append(Finding(\n",
    "            id=f\"G{len(findings)+1:02d}\",\n",
    "            category=\"Coverage Gap\",\n",
    "            severity=\"LOW\",\n",
    "            locations=[task.location],\n",
    "            summary=f\"Task {task.id} not mapped to any requirement\",\n",
    "            recommendation=f\"Link task {task.id} to specific requirement or mark as infrastructure\"\n",
    "        ))\n",
    "    \n",
    "    return findings, req_task_map\n",
    "\n",
    "def detect_inconsistencies(spec_sections: Dict[str, str], plan_sections: Dict[str, str], tasks: List[Task]) -> List[Finding]:\n",
    "    \"\"\"Detect terminology drift and inconsistencies across artifacts.\"\"\" \n",
    "    findings = []\n",
    "    \n",
    "    # Check for terminology variations\n",
    "    terminology_groups = [\n",
    "        ['game', 'title', 'app'],  # Game references\n",
    "        ['review', 'comment', 'feedback'],  # Review references  \n",
    "        ['search', 'query', 'lookup'],  # Search references\n",
    "        ['candidate', 'result', 'item'],  # Result references\n",
    "    ]\n",
    "    \n",
    "    all_text = spec_content + plan_content + tasks_content\n",
    "    \n",
    "    for group in terminology_groups:\n",
    "        used_terms = [term for term in group if term in all_text.lower()]\n",
    "        if len(used_terms) > 2:  # More than 2 variants used\n",
    "            findings.append(Finding(\n",
    "                id=f\"I{len(findings)+1:02d}\",\n",
    "                category=\"Inconsistency\",\n",
    "                severity=\"LOW\",\n",
    "                locations=[\"multiple files\"],\n",
    "                summary=f\"Multiple terms used for same concept: {used_terms}\",\n",
    "                recommendation=f\"Standardize on single term from: {used_terms}\"\n",
    "            ))\n",
    "    \n",
    "    return findings\n",
    "\n",
    "# Run all detection passes\n",
    "print(\"Running detection passes...\")\n",
    "\n",
    "duplication_findings = detect_duplications(requirements)\n",
    "ambiguity_findings = detect_ambiguities(requirements, tasks)\n",
    "underspec_findings = detect_underspecification(requirements, tasks)\n",
    "constitution_findings = detect_constitution_violations(requirements, constitution_principles)\n",
    "coverage_findings, req_task_map = detect_coverage_gaps(requirements, tasks) \n",
    "inconsistency_findings = detect_inconsistencies(spec_sections, plan_sections, tasks)\n",
    "\n",
    "all_findings = (duplication_findings + ambiguity_findings + underspec_findings + \n",
    "               constitution_findings + coverage_findings + inconsistency_findings)\n",
    "\n",
    "print(f\"Detection complete:\")\n",
    "print(f\"  Duplication issues: {len(duplication_findings)}\")\n",
    "print(f\"  Ambiguity issues: {len(ambiguity_findings)}\")\n",
    "print(f\"  Underspecification issues: {len(underspec_findings)}\")\n",
    "print(f\"  Constitution violations: {len(constitution_findings)}\")\n",
    "print(f\"  Coverage gaps: {len(coverage_findings)}\")\n",
    "print(f\"  Inconsistencies: {len(inconsistency_findings)}\")\n",
    "print(f\"  Total findings: {len(all_findings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7c9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Distribution:\n",
      "  CRITICAL: 0 issues\n",
      "  HIGH: 6 issues\n",
      "    Categories: {'Coverage Gap', 'Ambiguity'}\n",
      "  MEDIUM: 6 issues\n",
      "    Categories: {'Underspecification', 'Coverage Gap'}\n",
      "  LOW: 7 issues\n",
      "    Categories: {'Coverage Gap', 'Inconsistency'}\n",
      "\n",
      "⚠️  HIGH Priority Issues:\n",
      "  A01: Unresolved placeholder 'NEEDS CLARIFICATION' found in artifacts\n",
      "  G01: Requirement fr_003 has no associated tasks\n",
      "  G02: Requirement fr_005 has no associated tasks\n",
      "  G03: Requirement fr_007 has no associated tasks\n",
      "  G06: Requirement fr_011 has no associated tasks\n",
      "\n",
      "Total findings by category:\n",
      "  Ambiguity: 1\n",
      "  Coverage Gap: 12\n",
      "  Inconsistency: 2\n",
      "  Underspecification: 4\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Assign Severity Levels\n",
    "def categorize_by_severity(findings: List[Finding]) -> Dict[str, List[Finding]]:\n",
    "    \"\"\"Categorize findings by severity level.\"\"\"\n",
    "    severity_groups = {\n",
    "        'CRITICAL': [],\n",
    "        'HIGH': [],\n",
    "        'MEDIUM': [],\n",
    "        'LOW': []\n",
    "    }\n",
    "    \n",
    "    for finding in findings:\n",
    "        severity_groups[finding.severity].append(finding)\n",
    "    \n",
    "    return severity_groups\n",
    "\n",
    "def validate_severity_assignment(findings: List[Finding], constitution_principles: Dict[str, str]) -> None:\n",
    "    \"\"\"Validate and adjust severity based on constitution impact.\"\"\"\n",
    "    \n",
    "    for finding in findings:\n",
    "        # Constitution violations are always CRITICAL\n",
    "        if finding.category == \"Constitution\":\n",
    "            finding.severity = \"CRITICAL\"\n",
    "        \n",
    "        # Missing core functionality is HIGH\n",
    "        elif finding.category == \"Coverage Gap\" and \"MUST\" in finding.summary:\n",
    "            if finding.severity not in [\"CRITICAL\", \"HIGH\"]:\n",
    "                finding.severity = \"HIGH\"\n",
    "        \n",
    "        # Ambiguities in security/performance are HIGH  \n",
    "        elif finding.category == \"Ambiguity\" and any(term in finding.summary.lower() \n",
    "                                                   for term in ['security', 'performance', 'latency']):\n",
    "            if finding.severity == \"MEDIUM\":\n",
    "                finding.severity = \"HIGH\"\n",
    "\n",
    "# Apply severity validation\n",
    "validate_severity_assignment(all_findings, constitution_principles)\n",
    "\n",
    "# Categorize by severity\n",
    "severity_groups = categorize_by_severity(all_findings)\n",
    "\n",
    "print(\"Severity Distribution:\")\n",
    "for severity, findings in severity_groups.items():\n",
    "    print(f\"  {severity}: {len(findings)} issues\")\n",
    "    if findings:\n",
    "        print(f\"    Categories: {set(f.category for f in findings)}\")\n",
    "\n",
    "# Show critical issues first\n",
    "if severity_groups['CRITICAL']:\n",
    "    print(f\"\\n🚨 CRITICAL Issues (MUST be resolved before /implement):\")\n",
    "    for finding in severity_groups['CRITICAL']:\n",
    "        print(f\"  {finding.id}: {finding.summary}\")\n",
    "\n",
    "if severity_groups['HIGH']:\n",
    "    print(f\"\\n⚠️  HIGH Priority Issues:\")\n",
    "    for finding in severity_groups['HIGH'][:5]:  # Show first 5\n",
    "        print(f\"  {finding.id}: {finding.summary}\")\n",
    "        \n",
    "print(f\"\\nTotal findings by category:\")\n",
    "category_counts = {}\n",
    "for finding in all_findings:\n",
    "    category_counts[finding.category] = category_counts.get(finding.category, 0) + 1\n",
    "\n",
    "for category, count in sorted(category_counts.items()):\n",
    "    print(f\"  {category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a4a039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Specification Analysis Report\n",
       "**Analysis Date:** Wed Sep 24 14:35:30 UTC 2025\n",
       "**Feature Directory:** `/workspaces/ActualGameSearch_V3/specs/002-we-intend-to`\n",
       "\n",
       "## ⚠️ Executive Summary\n",
       "**HIGH PRIORITY ISSUES:** 6 issues should be addressed.\n",
       "Total issues: 19 (High: 6)\n",
       "\n",
       "## Findings Table\n",
       "| ID | Category | Severity | Location(s) | Summary | Recommendation |\n",
       "|----|----------|----------|-------------|---------|----------------|\n",
       "| A01 | Ambiguity | HIGH | multiple files | Unresolved placeholder 'NEEDS CLARIFICATION' found in artifacts | Resolve all 'NEEDS CLARIFICATION' markers before implementat... |\n",
       "| G01 | Coverage Gap | HIGH | spec.md#functional-requirements | Requirement fr_003 has no associated tasks | Add implementation tasks for requirement fr_003 |\n",
       "| G02 | Coverage Gap | HIGH | spec.md#functional-requirements | Requirement fr_005 has no associated tasks | Add implementation tasks for requirement fr_005 |\n",
       "| G03 | Coverage Gap | HIGH | spec.md#functional-requirements | Requirement fr_007 has no associated tasks | Add implementation tasks for requirement fr_007 |\n",
       "| G06 | Coverage Gap | HIGH | spec.md#functional-requirements | Requirement fr_011 has no associated tasks | Add implementation tasks for requirement fr_011 |\n",
       "| G07 | Coverage Gap | HIGH | spec.md#filtering-constraints | Requirement fr_028 has no associated tasks | Add implementation tasks for requirement fr_028 |\n",
       "| G04 | Coverage Gap | MEDIUM | spec.md#functional-requirements | Requirement fr_009 has no associated tasks | Add implementation tasks for requirement fr_009 |\n",
       "| G05 | Coverage Gap | MEDIUM | spec.md#functional-requirements | Requirement fr_010 has no associated tasks | Add implementation tasks for requirement fr_010 |\n",
       "| U01 | Underspecification | MEDIUM | tasks.md#phase-3.2:-tests-first-(tdd)-⚠️-must-complete-before-3.3 | Task T006 references undefined files: ['tests/ActualGameSearch.ContractTests/Gam... | Define referenced components in spec or plan |\n",
       "| U02 | Underspecification | MEDIUM | tasks.md#phase-3.2:-tests-first-(tdd)-⚠️-must-complete-before-3.3 | Task T007 references undefined files: ['tests/ActualGameSearch.ContractTests/Rev... | Define referenced components in spec or plan |\n",
       "| U03 | Underspecification | MEDIUM | tasks.md#phase-3.2:-tests-first-(tdd)-⚠️-must-complete-before-3.3 | Task T008 references undefined files: ['tests/ActualGameSearch.ContractTests/Sea... | Define referenced components in spec or plan |\n",
       "| U04 | Underspecification | MEDIUM | tasks.md#phase-3.5:-polish | Task T027 references undefined files: ['docs/data-dictionary.md'] | Define referenced components in spec or plan |\n",
       "| G08 | Coverage Gap | LOW | tasks.md#phase-3.1:-setup | Task T002 not mapped to any requirement | Link task T002 to specific requirement or mark as infrastruc... |\n",
       "| G09 | Coverage Gap | LOW | tasks.md#phase-3.1:-setup | Task T003 not mapped to any requirement | Link task T003 to specific requirement or mark as infrastruc... |\n",
       "| G10 | Coverage Gap | LOW | tasks.md#phase-3.1:-setup | Task T004 not mapped to any requirement | Link task T004 to specific requirement or mark as infrastruc... |\n",
       "| G11 | Coverage Gap | LOW | tasks.md#phase-3.2:-tests-first-(tdd)-⚠️-must-complete-before-3.3 | Task T005 not mapped to any requirement | Link task T005 to specific requirement or mark as infrastruc... |\n",
       "| G12 | Coverage Gap | LOW | tasks.md#phase-3.2:-tests-first-(tdd)-⚠️-must-complete-before-3.3 | Task T006 not mapped to any requirement | Link task T006 to specific requirement or mark as infrastruc... |\n",
       "| I01 | Inconsistency | LOW | multiple files | Multiple terms used for same concept: ['game', 'title', 'app'] | Standardize on single term from: ['game', 'title', 'app'] |\n",
       "| I02 | Inconsistency | LOW | multiple files | Multiple terms used for same concept: ['candidate', 'result', 'item'] | Standardize on single term from: ['candidate', 'result', 'it... |\n",
       "\n",
       "## Coverage Summary\n",
       "| Requirement Key | Has Task? | Task IDs | Notes |\n",
       "|-----------------|-----------|----------|-------|\n",
       "| fr_001 | Yes | T009, T014, T015, T017, T021, T023 | ✅ Covered |\n",
       "| fr_002 | Yes | T009, T023 | ✅ Covered |\n",
       "| fr_003 | No | None | ❌ No coverage |\n",
       "| fr_004 | Yes | T009, T023 | ✅ Covered |\n",
       "| fr_005 | No | None | ❌ No coverage |\n",
       "| fr_006 | Yes | T009, T010, T014, T015, T021, T023 | ✅ Covered |\n",
       "| fr_007 | No | None | ❌ No coverage |\n",
       "| fr_008 | Yes | T014, T021 | ✅ Covered |\n",
       "| fr_009 | No | None | ❌ No coverage |\n",
       "| fr_010 | No | None | ❌ No coverage |\n",
       "| fr_011 | No | None | ❌ No coverage |\n",
       "| fr_012 | Yes | T009, T015, T017, T023 | ✅ Covered |\n",
       "| fr_013 | Yes | T009, T010, T014, T015, T017, T021, T023, T027 | ✅ Covered |\n",
       "| fr_020 | Yes | T009, T010, T014, T015, T023 | ✅ Covered |\n",
       "| fr_021 | Yes | T016 | ✅ Covered |\n",
       "| fr_022 | Yes | T009, T010, T014, T015, T021, T023 | ✅ Covered |\n",
       "| fr_023 | Yes | T009, T014, T015, T021, T023, T025 | ✅ Covered |\n",
       "| fr_024 | Yes | T009, T023 | ✅ Covered |\n",
       "| fr_025 | Yes | T014, T015, T016, T021 | ✅ Covered |\n",
       "| fr_026 | Yes | T001, T009, T010, T014, T015, T016, T017, T018, T019, T020, T021, T023 | ✅ Covered |\n",
       "| fr_027 | Yes | T009, T010, T014, T015, T016, T023, T025 | ✅ Covered |\n",
       "| fr_028 | No | None | ❌ No coverage |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Generate Analysis Report\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def generate_findings_table(findings: List[Finding], limit: int = 50) -> str:\n",
    "    \"\"\"Generate markdown table of findings.\"\"\"\n",
    "    \n",
    "    # Limit to top findings (by severity order: CRITICAL, HIGH, MEDIUM, LOW)\n",
    "    severity_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}\n",
    "    sorted_findings = sorted(findings, key=lambda f: (severity_order[f.severity], f.id))[:limit]\n",
    "    \n",
    "    table_lines = [\n",
    "        \"| ID | Category | Severity | Location(s) | Summary | Recommendation |\",\n",
    "        \"|----|----------|----------|-------------|---------|----------------|\"\n",
    "    ]\n",
    "    \n",
    "    for finding in sorted_findings:\n",
    "        locations_str = \", \".join(finding.locations) if len(finding.locations) <= 2 else f\"{finding.locations[0]} +{len(finding.locations)-1} more\"\n",
    "        summary_short = finding.summary[:80] + \"...\" if len(finding.summary) > 80 else finding.summary\n",
    "        recommendation_short = finding.recommendation[:60] + \"...\" if len(finding.recommendation) > 60 else finding.recommendation\n",
    "        \n",
    "        table_lines.append(f\"| {finding.id} | {finding.category} | {finding.severity} | {locations_str} | {summary_short} | {recommendation_short} |\")\n",
    "    \n",
    "    return \"\\n\".join(table_lines)\n",
    "\n",
    "def generate_coverage_summary(requirements: List[Requirement], req_task_map: Dict[str, List[str]]) -> str:\n",
    "    \"\"\"Generate requirements coverage summary table.\"\"\"\n",
    "    \n",
    "    table_lines = [\n",
    "        \"| Requirement Key | Has Task? | Task IDs | Notes |\",\n",
    "        \"|-----------------|-----------|----------|-------|\"\n",
    "    ]\n",
    "    \n",
    "    for req in requirements:\n",
    "        has_tasks = bool(req_task_map[req.key])\n",
    "        task_ids = \", \".join(req_task_map[req.key]) if req_task_map[req.key] else \"None\"\n",
    "        notes = \"✅ Covered\" if has_tasks else \"❌ No coverage\"\n",
    "        \n",
    "        table_lines.append(f\"| {req.key} | {'Yes' if has_tasks else 'No'} | {task_ids} | {notes} |\")\n",
    "    \n",
    "    return \"\\n\".join(table_lines)\n",
    "\n",
    "# Generate the main analysis report\n",
    "report_sections = []\n",
    "\n",
    "# Header\n",
    "report_sections.append(\"# Specification Analysis Report\")\n",
    "report_sections.append(f\"**Analysis Date:** {os.popen('date').read().strip()}\")\n",
    "report_sections.append(f\"**Feature Directory:** `{FEATURE_DIR}`\")\n",
    "report_sections.append(\"\")\n",
    "\n",
    "# Executive Summary\n",
    "critical_count = len(severity_groups['CRITICAL'])\n",
    "high_count = len(severity_groups['HIGH']) \n",
    "total_count = len(all_findings)\n",
    "\n",
    "if critical_count > 0:\n",
    "    report_sections.append(\"## 🚨 Executive Summary\")\n",
    "    report_sections.append(f\"**CRITICAL ISSUES FOUND:** {critical_count} issues must be resolved before implementation.\")\n",
    "    report_sections.append(f\"Total issues: {total_count} (Critical: {critical_count}, High: {high_count})\")\n",
    "    report_sections.append(\"\")\n",
    "elif high_count > 5:\n",
    "    report_sections.append(\"## ⚠️ Executive Summary\") \n",
    "    report_sections.append(f\"**HIGH PRIORITY ISSUES:** {high_count} issues should be addressed.\")\n",
    "    report_sections.append(f\"Total issues: {total_count} (High: {high_count})\")\n",
    "    report_sections.append(\"\")\n",
    "else:\n",
    "    report_sections.append(\"## ✅ Executive Summary\")\n",
    "    report_sections.append(f\"**ANALYSIS PASSED:** No critical issues found. {total_count} total issues identified.\")\n",
    "    report_sections.append(\"\")\n",
    "\n",
    "# Main findings table\n",
    "report_sections.append(\"## Findings Table\")\n",
    "findings_table = generate_findings_table(all_findings)\n",
    "report_sections.append(findings_table)\n",
    "report_sections.append(\"\")\n",
    "\n",
    "if len(all_findings) > 50:\n",
    "    report_sections.append(f\"*Note: Table limited to top 50 findings. {len(all_findings) - 50} additional findings exist.*\")\n",
    "    report_sections.append(\"\")\n",
    "\n",
    "# Coverage summary\n",
    "report_sections.append(\"## Coverage Summary\")\n",
    "coverage_table = generate_coverage_summary(requirements, req_task_map)\n",
    "report_sections.append(coverage_table)\n",
    "report_sections.append(\"\")\n",
    "\n",
    "# Constitution alignment\n",
    "if constitution_findings:\n",
    "    report_sections.append(\"## Constitution Alignment Issues\")\n",
    "    for finding in constitution_findings:\n",
    "        report_sections.append(f\"- **{finding.id}:** {finding.summary}\")\n",
    "        report_sections.append(f\"  - *Recommendation:* {finding.recommendation}\")\n",
    "    report_sections.append(\"\")\n",
    "\n",
    "# Generate final report markdown\n",
    "report_markdown = \"\\n\".join(report_sections)\n",
    "\n",
    "# Display the report\n",
    "display(Markdown(report_markdown))\n",
    "\n",
    "print(\"Report generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05df13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Coverage and Quality Metrics:\n",
      "  Total Requirements: 22 (Functional: 22, Non-functional: 0)\n",
      "  Total Tasks: 28 (Parallel: 0)\n",
      "  Coverage: 68.2% (15/22 requirements have tasks)\n",
      "  Quality Issues: 19 total (0 critical, 6 high)\n",
      "  Constitution Violations: 0\n",
      "  Ambiguities: 1\n",
      "  Duplications: 0\n",
      "\n",
      "📋 Task Distribution by Phase:\n",
      "  Phase 3.1: Setup: 4 tasks\n",
      "  Phase 3.2: Tests First (TDD) ⚠️ MUST COMPLETE BEFORE 3.3: 6 tasks\n",
      "  Phase 3.3: Core Implementation (ONLY after tests are failing): 10 tasks\n",
      "  Phase 3.4: Integration: 4 tasks\n",
      "  Phase 3.5: Polish: 4 tasks\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Metrics Summary\n",
       "\n",
       "**Requirements Coverage:**\n",
       "- Total Requirements: 22 (Functional: 22, Non-functional: 0)\n",
       "- Requirements with Tasks: 15/22\n",
       "- Coverage Percentage: 68.2%\n",
       "\n",
       "**Task Analysis:**\n",
       "- Total Tasks: 28\n",
       "- Parallel Tasks: 0\n",
       "\n",
       "**Quality Assessment:**\n",
       "- Total Findings: 19\n",
       "- Critical Issues: 0\n",
       "- High Priority Issues: 6\n",
       "- Constitution Violations: 0\n",
       "- Ambiguity Count: 1\n",
       "- Duplication Count: 0\n",
       "\n",
       "**Task Distribution:**\n",
       "- Phase 3.1: Setup: 4 tasks\n",
       "- Phase 3.2: Tests First (TDD) ⚠️ MUST COMPLETE BEFORE 3.3: 6 tasks\n",
       "- Phase 3.3: Core Implementation (ONLY after tests are failing): 10 tasks\n",
       "- Phase 3.4: Integration: 4 tasks\n",
       "- Phase 3.5: Polish: 4 tasks\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Section 7: Calculate Coverage Metrics\n",
    "def calculate_coverage_metrics(requirements: List[Requirement], tasks: List[Task], \n",
    "                              req_task_map: Dict[str, List[str]], all_findings: List[Finding]) -> Dict[str, Any]:\n",
    "    \"\"\"Calculate comprehensive coverage and quality metrics.\"\"\"\n",
    "    \n",
    "    # Basic counts\n",
    "    total_requirements = len(requirements)\n",
    "    functional_requirements = len([r for r in requirements if r.requirement_type == 'functional'])\n",
    "    non_functional_requirements = len([r for r in requirements if r.requirement_type == 'non-functional'])\n",
    "    total_tasks = len(tasks)\n",
    "    \n",
    "    # Coverage metrics\n",
    "    requirements_with_tasks = len([req for req in requirements if req_task_map[req.key]])\n",
    "    coverage_percentage = (requirements_with_tasks / total_requirements * 100) if total_requirements > 0 else 0\n",
    "    \n",
    "    # Quality metrics\n",
    "    ambiguity_count = len([f for f in all_findings if f.category == \"Ambiguity\"])\n",
    "    duplication_count = len([f for f in all_findings if f.category == \"Duplication\"])\n",
    "    critical_issues_count = len([f for f in all_findings if f.severity == \"CRITICAL\"])\n",
    "    high_issues_count = len([f for f in all_findings if f.severity == \"HIGH\"])\n",
    "    \n",
    "    # Task distribution\n",
    "    phase_distribution = {}\n",
    "    parallel_tasks = 0\n",
    "    for task in tasks:\n",
    "        phase_distribution[task.phase] = phase_distribution.get(task.phase, 0) + 1\n",
    "        if task.parallel:\n",
    "            parallel_tasks += 1\n",
    "    \n",
    "    # Constitution compliance\n",
    "    constitution_violations = len([f for f in all_findings if f.category == \"Constitution\"])\n",
    "    \n",
    "    return {\n",
    "        'total_requirements': total_requirements,\n",
    "        'functional_requirements': functional_requirements, \n",
    "        'non_functional_requirements': non_functional_requirements,\n",
    "        'total_tasks': total_tasks,\n",
    "        'requirements_with_tasks': requirements_with_tasks,\n",
    "        'coverage_percentage': coverage_percentage,\n",
    "        'ambiguity_count': ambiguity_count,\n",
    "        'duplication_count': duplication_count,\n",
    "        'critical_issues_count': critical_issues_count,\n",
    "        'high_issues_count': high_issues_count,\n",
    "        'total_findings': len(all_findings),\n",
    "        'phase_distribution': phase_distribution,\n",
    "        'parallel_tasks': parallel_tasks,\n",
    "        'constitution_violations': constitution_violations\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_coverage_metrics(requirements, tasks, req_task_map, all_findings)\n",
    "\n",
    "print(\"📊 Coverage and Quality Metrics:\")\n",
    "print(f\"  Total Requirements: {metrics['total_requirements']} (Functional: {metrics['functional_requirements']}, Non-functional: {metrics['non_functional_requirements']})\")\n",
    "print(f\"  Total Tasks: {metrics['total_tasks']} (Parallel: {metrics['parallel_tasks']})\")\n",
    "print(f\"  Coverage: {metrics['coverage_percentage']:.1f}% ({metrics['requirements_with_tasks']}/{metrics['total_requirements']} requirements have tasks)\")\n",
    "print(f\"  Quality Issues: {metrics['total_findings']} total ({metrics['critical_issues_count']} critical, {metrics['high_issues_count']} high)\")\n",
    "print(f\"  Constitution Violations: {metrics['constitution_violations']}\")\n",
    "print(f\"  Ambiguities: {metrics['ambiguity_count']}\")\n",
    "print(f\"  Duplications: {metrics['duplication_count']}\")\n",
    "\n",
    "print(f\"\\n📋 Task Distribution by Phase:\")\n",
    "for phase, count in sorted(metrics['phase_distribution'].items()):\n",
    "    print(f\"  {phase}: {count} tasks\")\n",
    "\n",
    "# Create metrics summary for report\n",
    "metrics_section = f\"\"\"\n",
    "## Metrics Summary\n",
    "\n",
    "**Requirements Coverage:**\n",
    "- Total Requirements: {metrics['total_requirements']} (Functional: {metrics['functional_requirements']}, Non-functional: {metrics['non_functional_requirements']})\n",
    "- Requirements with Tasks: {metrics['requirements_with_tasks']}/{metrics['total_requirements']}\n",
    "- Coverage Percentage: {metrics['coverage_percentage']:.1f}%\n",
    "\n",
    "**Task Analysis:**\n",
    "- Total Tasks: {metrics['total_tasks']}\n",
    "- Parallel Tasks: {metrics['parallel_tasks']}\n",
    "\n",
    "**Quality Assessment:**\n",
    "- Total Findings: {metrics['total_findings']}\n",
    "- Critical Issues: {metrics['critical_issues_count']}\n",
    "- High Priority Issues: {metrics['high_issues_count']}\n",
    "- Constitution Violations: {metrics['constitution_violations']}\n",
    "- Ambiguity Count: {metrics['ambiguity_count']}\n",
    "- Duplication Count: {metrics['duplication_count']}\n",
    "\n",
    "**Task Distribution:**\n",
    "\"\"\"\n",
    "\n",
    "for phase, count in sorted(metrics['phase_distribution'].items()):\n",
    "    metrics_section += f\"- {phase}: {count} tasks\\n\"\n",
    "\n",
    "display(Markdown(metrics_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c9f0ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ⚠️ HIGH PRIORITY RECOMMENDATIONS\n",
       "**6 high-priority issues should be addressed.**\n",
       "You may proceed to implementation, but consider resolving these first:\n",
       "\n",
       "- **A01**: Unresolved placeholder 'NEEDS CLARIFICATION' found in artifacts\n",
       "  - Suggested: Resolve all 'NEEDS CLARIFICATION' markers before implementation\n",
       "\n",
       "- **G01**: Requirement fr_003 has no associated tasks\n",
       "  - Suggested: Add implementation tasks for requirement fr_003\n",
       "\n",
       "- **G02**: Requirement fr_005 has no associated tasks\n",
       "  - Suggested: Add implementation tasks for requirement fr_005\n",
       "\n",
       "- **G03**: Requirement fr_007 has no associated tasks\n",
       "  - Suggested: Add implementation tasks for requirement fr_007\n",
       "\n",
       "- **G06**: Requirement fr_011 has no associated tasks\n",
       "  - Suggested: Add implementation tasks for requirement fr_011\n",
       "\n",
       "## 📋 COVERAGE IMPROVEMENT\n",
       "**Coverage is 68.2%** - 7 requirements lack task coverage.\n",
       "\n",
       "Uncovered requirements:\n",
       "- `fr_003`: The system MUST support a “similar games” action from any re...\n",
       "- `fr_005`: The system MUST provide actionable, non-technical error mess...\n",
       "- `fr_007`: The system MUST enforce basic rate limiting to protect from ...\n",
       "- `fr_009`: The system SHOULD allow exploration of related games via mul...\n",
       "- `fr_010`: The system MAY support visual exploration of embeddings (2D/...\n",
       "- `fr_011`: The experience MUST be responsive and accessible.\n",
       "-...\n",
       "- `fr_028`: The system MUST allow including/excluding “singleton” games ...\n",
       "\n",
       "**Recommended:** Manually edit `tasks.md` to add coverage for missing requirements.\n",
       "\n",
       "## 🔍 IMPLEMENTATION READINESS CHECKLIST\n",
       "- [x] No critical constitution violations\n",
       "- [ ] Requirements coverage ≥ 70% (68.2%)\n",
       "- [x] Ambiguities manageable (≤ 5, found 1)\n",
       "- [x] No requirement duplications (0 found)\n",
       "\n",
       "## 🛠️ SPECIFIC COMMAND RECOMMENDATIONS\n",
       "- Manually edit `tasks.md` to add missing coverage\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📋 ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "⚠️  PROCEED WITH CAUTION: 6 high-priority issues found.\n",
      "   Recommendation: Consider addressing major issues before implementation.\n",
      "\n",
      "Total Issues: 19 | Coverage: 68.2%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔧 Would you like me to suggest concrete remediation edits for the top issues?\n",
      "   (Note: I will NOT apply edits automatically - I will only suggest specific changes)\n",
      "\n",
      "💾 Analysis results stored in 'analysis_results' variable for further processing.\n"
     ]
    }
   ],
   "source": [
    "# Section 8: Provide Next Actions and Remediation Recommendations\n",
    "\n",
    "def generate_next_actions(metrics: Dict[str, Any], severity_groups: Dict[str, List[Finding]], \n",
    "                         requirements: List[Requirement], tasks: List[Task]) -> str:\n",
    "    \"\"\"Generate next actions based on analysis results.\"\"\"\n",
    "    \n",
    "    actions = []\n",
    "    \n",
    "    # Critical issues block implementation\n",
    "    if metrics['critical_issues_count'] > 0:\n",
    "        actions.append(\"## 🚨 IMMEDIATE ACTIONS REQUIRED\")\n",
    "        actions.append(f\"**CRITICAL ISSUES MUST BE RESOLVED before `/implement` command.**\")\n",
    "        actions.append(\"\")\n",
    "        \n",
    "        for finding in severity_groups['CRITICAL']:\n",
    "            actions.append(f\"1. **{finding.id}**: {finding.summary}\")\n",
    "            actions.append(f\"   - Action: {finding.recommendation}\")\n",
    "            actions.append(\"\")\n",
    "        \n",
    "        actions.append(\"**Recommended Commands:**\")\n",
    "        if any('Constitution' in f.category for f in severity_groups['CRITICAL']):\n",
    "            actions.append(\"- Review constitution alignment and update spec/plan accordingly\")\n",
    "        actions.append(\"- `Run /specify` to refine requirements\")\n",
    "        actions.append(\"- `Run /plan` to adjust architecture if needed\")\n",
    "        actions.append(\"\")\n",
    "    \n",
    "    # High priority recommendations\n",
    "    elif metrics['high_issues_count'] > 0:\n",
    "        actions.append(\"## ⚠️ HIGH PRIORITY RECOMMENDATIONS\")\n",
    "        actions.append(f\"**{metrics['high_issues_count']} high-priority issues should be addressed.**\")\n",
    "        actions.append(\"You may proceed to implementation, but consider resolving these first:\")\n",
    "        actions.append(\"\")\n",
    "        \n",
    "        for finding in severity_groups['HIGH'][:5]:  # Show top 5\n",
    "            actions.append(f\"- **{finding.id}**: {finding.summary}\")\n",
    "            actions.append(f\"  - Suggested: {finding.recommendation}\")\n",
    "            actions.append(\"\")\n",
    "    \n",
    "    # Medium/Low issues guidance\n",
    "    if metrics['coverage_percentage'] < 80:\n",
    "        actions.append(\"## 📋 COVERAGE IMPROVEMENT\")\n",
    "        uncovered_reqs = [req for req in requirements if not req_task_map[req.key]]\n",
    "        actions.append(f\"**Coverage is {metrics['coverage_percentage']:.1f}%** - {len(uncovered_reqs)} requirements lack task coverage.\")\n",
    "        actions.append(\"\")\n",
    "        actions.append(\"Uncovered requirements:\")\n",
    "        for req in uncovered_reqs[:10]:  # Show first 10\n",
    "            actions.append(f\"- `{req.key}`: {req.text[:60]}...\")\n",
    "        actions.append(\"\")\n",
    "        actions.append(\"**Recommended:** Manually edit `tasks.md` to add coverage for missing requirements.\")\n",
    "        actions.append(\"\")\n",
    "    \n",
    "    # Success case\n",
    "    if metrics['critical_issues_count'] == 0 and metrics['high_issues_count'] <= 2:\n",
    "        actions.append(\"## ✅ READY TO PROCEED\")\n",
    "        actions.append(\"**Analysis PASSED** - No critical blockers found.\")\n",
    "        actions.append(\"\")\n",
    "        actions.append(\"**Recommended Next Steps:**\")\n",
    "        actions.append(\"1. Run `/implement` to begin implementation\")\n",
    "        actions.append(\"2. Address remaining issues during implementation as needed\")\n",
    "        actions.append(\"\")\n",
    "    \n",
    "    # Implementation readiness checklist\n",
    "    actions.append(\"## 🔍 IMPLEMENTATION READINESS CHECKLIST\")\n",
    "    actions.append(f\"- [{'x' if metrics['critical_issues_count'] == 0 else ' '}] No critical constitution violations\")\n",
    "    actions.append(f\"- [{'x' if metrics['coverage_percentage'] >= 70 else ' '}] Requirements coverage ≥ 70% ({metrics['coverage_percentage']:.1f}%)\")\n",
    "    actions.append(f\"- [{'x' if metrics['ambiguity_count'] <= 5 else ' '}] Ambiguities manageable (≤ 5, found {metrics['ambiguity_count']})\")\n",
    "    actions.append(f\"- [{'x' if metrics['duplication_count'] == 0 else ' '}] No requirement duplications ({metrics['duplication_count']} found)\")\n",
    "    actions.append(\"\")\n",
    "    \n",
    "    # Specific command recommendations\n",
    "    actions.append(\"## 🛠️ SPECIFIC COMMAND RECOMMENDATIONS\")\n",
    "    \n",
    "    if metrics['constitution_violations'] > 0:\n",
    "        actions.append(\"- `Run /specify` with constitutional compliance focus\")\n",
    "        \n",
    "    if metrics['coverage_percentage'] < 70:\n",
    "        actions.append(f\"- Manually edit `tasks.md` to add missing coverage\")\n",
    "        \n",
    "    if metrics['ambiguity_count'] > 5:\n",
    "        actions.append(\"- Run `/specify` to clarify ambiguous requirements\")\n",
    "        \n",
    "    if metrics['duplication_count'] > 0:\n",
    "        actions.append(\"- Run `/specify` to consolidate duplicate requirements\")\n",
    "    \n",
    "    if len([f for f in all_findings if f.category == \"Inconsistency\"]) > 3:\n",
    "        actions.append(\"- Run `/plan` to standardize terminology across artifacts\")\n",
    "    \n",
    "    actions.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(actions)\n",
    "\n",
    "# Generate next actions\n",
    "next_actions = generate_next_actions(metrics, severity_groups, requirements, tasks)\n",
    "\n",
    "# Display next actions\n",
    "display(Markdown(next_actions))\n",
    "\n",
    "# Final user prompt\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if metrics['critical_issues_count'] > 0:\n",
    "    print(f\"⚠️  BLOCKED: {metrics['critical_issues_count']} critical issues must be resolved before implementation.\")\n",
    "    print(\"   Recommendation: Address critical issues first, then re-run analysis.\")\n",
    "elif metrics['high_issues_count'] > 5:\n",
    "    print(f\"⚠️  PROCEED WITH CAUTION: {metrics['high_issues_count']} high-priority issues found.\")\n",
    "    print(\"   Recommendation: Consider addressing major issues before implementation.\")\n",
    "else:\n",
    "    print(\"✅ READY TO PROCEED: No critical blockers found.\")\n",
    "    print(\"   Recommendation: You may proceed with /implement.\")\n",
    "\n",
    "print(f\"\\nTotal Issues: {metrics['total_findings']} | Coverage: {metrics['coverage_percentage']:.1f}%\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Ask user about remediation\n",
    "print(\"\\n🔧 Would you like me to suggest concrete remediation edits for the top issues?\")\n",
    "print(\"   (Note: I will NOT apply edits automatically - I will only suggest specific changes)\")\n",
    "\n",
    "# Store analysis results for potential follow-up\n",
    "analysis_results = {\n",
    "    'metrics': metrics,\n",
    "    'findings': all_findings,\n",
    "    'severity_groups': severity_groups,\n",
    "    'requirements': requirements,\n",
    "    'tasks': tasks,\n",
    "    'req_task_map': req_task_map\n",
    "}\n",
    "\n",
    "print(f\"\\n💾 Analysis results stored in 'analysis_results' variable for further processing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
